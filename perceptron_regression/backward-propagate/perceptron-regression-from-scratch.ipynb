{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G75-MZIlRGkv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O537lmEMRGkw"
   },
   "outputs": [],
   "source": [
    "def polynom_orig(x):\n",
    "    return np.cos(2 * np.pi * x)\n",
    "\n",
    "def error(x):\n",
    "    return polynom_orig(x) + random.normalvariate(-0.1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2bsCqIdnb1q"
   },
   "outputs": [],
   "source": [
    "def generate(N):\n",
    "    x = np.sort(np.random.uniform(0, 1., N))\n",
    "    x1 = x[::2]\n",
    "    x2 = x[1::2]\n",
    "    y = np.array(list(map(polynom_orig, x)))\n",
    "    y1 = np.array(list(map(error, x1)))\n",
    "    y2 = np.array(list(map(error, x2)))\n",
    "\n",
    "    return x1, y1, x2, y2, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6wTns9rcKfA"
   },
   "outputs": [],
   "source": [
    "def mse(train, predict):\n",
    "    return ((train - predict) ** 2).sum() / len(train)\n",
    "\n",
    "def rmse(train, predict):\n",
    "    return mse(train, predict) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERqk88uyRGkx"
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = np.random.normal(loc=0.0, \n",
    "                                        scale = np.sqrt(2 / (input_size + 1 + output_size)),\n",
    "                                        size=(output_size, input_size + 1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = np.hstack((input, np.ones(1)))\n",
    "        return self.weights @ input, input\n",
    "\n",
    "    def grad(self, delta, input, prev_activation):\n",
    "        dtanh = 1.0 / np.cosh(prev_activation) ** 2\n",
    "        dtanh = dtanh.reshape(1, dtanh.shape[0]).T\n",
    "        grad_out = dtanh @ input.reshape(1, input.shape[0])\n",
    "        grad_w = (delta.reshape(1, delta.shape[0])).T * grad_out\n",
    "        delta = self.weights.T @ delta\n",
    "        delta = delta[:self.input_size]\n",
    "        return grad_w, delta\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, input_size, first_layer_size, second_layer_size, output_layer_size):\n",
    "        self.input_size = input_size\n",
    "        self.first_layer_size = first_layer_size\n",
    "        self.second_layer_size = second_layer_size\n",
    "        self.output_layer_size = output_layer_size\n",
    "        \n",
    "        self.layer1 = Layer(input_size, first_layer_size)\n",
    "        self.layer2 = Layer(first_layer_size, second_layer_size)\n",
    "        self.layer3 = Layer(second_layer_size, output_layer_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out1, input1 = self.layer1.forward(input)\n",
    "        tanh1 = np.tanh(out1)\n",
    "        \n",
    "        out2, input2 = self.layer2.forward(tanh1)\n",
    "        tanh2 = np.tanh(out2)\n",
    "        \n",
    "        out3, input3 = self.layer3.forward(tanh2)\n",
    "        tanh3 = np.tanh(out3)\n",
    "        \n",
    "        return [input1, input2, input3], [out1, out2, out3], [tanh1, tanh2, tanh3]\n",
    "\n",
    "    def _update_weights(self, gradients, lr):\n",
    "        self.layer1.weights -= lr * gradients[0]\n",
    "        self.layer2.weights -= lr * gradients[1]\n",
    "        self.layer3.weights -= lr * gradients[2]\n",
    "\n",
    "    def fit(self, lr, epoch_count, train_X, train_Y, verbose = True):\n",
    "        mse_list = []\n",
    "        \n",
    "        for i in range(epoch_count):\n",
    "            grads = [np.zeros_like(self.layer1.weights),\n",
    "                     np.zeros_like(self.layer2.weights),\n",
    "                     np.zeros_like(self.layer3.weights)]\n",
    "            \n",
    "            avg_mse = 0.0\n",
    "            for j in range(len(train_X)):\n",
    "                x = train_X[j]\n",
    "                y = train_Y[j]\n",
    "                \n",
    "                [input1, input2, input3], [out1, out2, out3], prev_outputs = self.forward(x)\n",
    "                \n",
    "                error = prev_outputs[-1] - y\n",
    "                w3_grad, error = self.layer3.grad(error, input3, out3)\n",
    "                w2_grad, error = self.layer2.grad(error, input2, out2)\n",
    "                w1_grad, error = self.layer1.grad(error, input1, out1)\n",
    "                \n",
    "                grads[0] += w1_grad\n",
    "                grads[1] += w2_grad\n",
    "                grads[2] += w3_grad\n",
    "                \n",
    "                avg_mse += mse(prev_outputs[-1], y)\n",
    "            \n",
    "            avg_mse /= len(train_X)\n",
    "            \n",
    "            if (i % 100 == 0 and verbose):\n",
    "              print(\"epoch: \", i, \": MSE = \", avg_mse)\n",
    "            \n",
    "            mse_list.append(avg_mse)\n",
    "            self._update_weights(grads, lr)\n",
    "        return mse_list\n",
    "\n",
    "    def eval(self, test_X, test_Y):\n",
    "        res = []\n",
    "        error_list = []\n",
    "        \n",
    "        for i in range(len(test_X)):\n",
    "            x = test_X[i]\n",
    "            y = test_Y[i]\n",
    "            _, _, prev_outputs = self.forward(x)\n",
    "            res.append(prev_outputs[-1])\n",
    "            error_list.append(mse(prev_outputs[-1], y))\n",
    "        \n",
    "        return res, error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "5r-AjZO1apxS",
    "outputId": "d854a7f7-c593-445d-942c-939bc5c4c478"
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "trainX, trainY, testX, testY, allX, allY = generate(N)\n",
    "\n",
    "z = np.linspace(0., 1., 100)\n",
    "plt.title('Original polinom and train set')\n",
    "plt.plot(z, polynom_orig(z), 'b-')\n",
    "plt.plot(trainX, trainY, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOkwbvUhZdmX"
   },
   "outputs": [],
   "source": [
    "model = MLP(1, 5, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "av4WTM1_RGkz",
    "outputId": "13ab5a10-b3f5-4deb-ac58-c2100cb042e1"
   },
   "outputs": [],
   "source": [
    "print(\"Training:\")\n",
    "model.fit(0.001, 1000000, trainX, trainY)\n",
    "\n",
    "res, errs = model.eval(testX, testY)\n",
    "sqrt_errs = np.sqrt(errs)\n",
    "rmse = np.sum(sqrt_errs) / len(sqrt_errs)\n",
    "\n",
    "print(\"RMSE on test: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "Y88322fe9yYP",
    "outputId": "c22b0aa1-e331-4f49-bd11-6a125284edf1"
   },
   "outputs": [],
   "source": [
    "plt.title(\"Original and predicted:\")\n",
    "plt.plot(z, polynom_orig(z), 'b-')\n",
    "plt.plot(testX, res, 'g-')\n",
    "plt.plot(trainX, trainY, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "IhzOQwcTBspi",
    "outputId": "d4d5bccc-ca78-470e-902b-2540c36b7f6f"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for lr in np.arange(0.0, 0.1, 0.001):\n",
    "    for j in range(500, 2000, 500):\n",
    "      model = MLP(1, 5, 5, 1)\n",
    "      model.fit(lr, j, trainX, trainY, False)\n",
    "      \n",
    "      res, errs = model.eval(testX, testY)\n",
    "      sqrt_errs = np.sqrt(errs)\n",
    "      rmse = np.sum(sqrt_errs) / len(sqrt_errs)\n",
    "      \n",
    "      print(\"RMSE for learning rate = \" + str(lr) + \" and epoch number = \" + str(j) + \", rmse = \", rmse)\n",
    "      results.append((lr, j, rmse, res))\n",
    "\n",
    "sorted_res = sorted(results, key=lambda t: t[2])\n",
    "for t in sorted_res:\n",
    "    print('Learning rate = ', t[0], ' epoch number = ', t[1], ' Err = ', t[2])\n",
    "\n",
    "plt.title(\"Original and best predicted:\")\n",
    "plt.plot(z, polynom_orig(z), 'b-')\n",
    "plt.plot(testX, sorted_res[0][3], 'g-')\n",
    "plt.plot(trainX, trainY, 'ro')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97e5078213819e0972490c34bb51c0691090174e06a5f50748383c443c04f591"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
